{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "from copy import deepcopy\n",
                "import yaml\n",
                "from pathlib import Path\n",
                "import torch\n",
                "import numpy as np\n",
                "import shutil\n",
                "import matplotlib.pyplot as plt\n",
                "from postprocessing.visualization import _aligned_colorbar\n",
                "\n",
                "from extend_plumes import cut_dataset_in_pieces, prepare_dataset_for_2levels, pipeline\n",
                "from main import run, save_inference\n",
                "from data_stuff.utils import SettingsTraining\n",
                "from preprocessing.prepare import prepare_data_and_paths\n",
                "\n",
                "\n",
                "%reload_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Application to small dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_prep = \"dataset_2d_small_100dp inputs_gksi\"\n",
                "number_boxes = 4\n",
                "inputs_prop = \"t\"\n",
                "with open(\"paths.yaml\", \"r\") as paths:\n",
                "\tpaths = yaml.safe_load(paths)\n",
                "\tprepared1_dir = Path(paths[\"datasets_prepared_dir\"]) / dataset_prep\n",
                "\tprepared_pieces_dir = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_prep} cut_{number_boxes}pieces separate_boxes\"\n",
                "\tprepared_pieces_dir.mkdir(parents=True, exist_ok=True)\n",
                "cut_dataset_in_pieces(number_boxes, prepared1_dir, prepared_pieces_dir)\n",
                "prepare_dataset_for_2levels(dataset_prep, number_boxes, \"t\", paths, prepared1_dir, prepared_pieces_dir)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## TODO in between: run 2 models on prior prepared datasets"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pipeline to test the predictions of the models of both levels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# dataset_prep = \"dataset_2d_small_100dp inputs_gksi invert cut_4pieces separate_boxes\"\n",
                "# model = \"dataset_100dp_invert inputs_t case_train\"\n",
                "dataset_prep = \"dataset_2d_small_100dp inputs_gksi cut_4pieces separate_boxes\"\n",
                "model = \"model cut_4pieces separate_boxes 2nd level t without_last_box\"\n",
                "for id in range(10):\n",
                "    pipeline(id, dataset_prep, \"t\", nr_boxes_orig=4, model=model)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cut and test medium domain"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# prepare dataset\n",
                "dataset_prep = \"dataset_medium_k_3e-10_1000dp\"\n",
                "inputs = \"gksi\"\n",
                "\n",
                "args = {}\n",
                "args[\"dataset_raw\"] = dataset_prep\n",
                "args[\"dataset_prep\"] = \"\"\n",
                "args[\"device\"] = \"cuda:3\"\n",
                "args[\"epochs\"] = 1\n",
                "args[\"case\"] = \"finetune\"\n",
                "args[\"model\"] = \"model cut_4pieces separate_boxes 1st level\"\n",
                "args[\"destination\"] = \"\"\n",
                "args[\"inputs\"] = inputs\n",
                "args[\"case_2hp\"] = False\n",
                "args[\"visualize\"] = False\n",
                "args[\"save_inference\"] = False\n",
                "settings = SettingsTraining(**args)\n",
                "\n",
                "settings = prepare_data_and_paths(settings)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_prep = \"dataset_medium_k_3e-10_1000dp inputs_gksi\" #dataset_small_long_1hp_100dp_interim inputs_gksi\n",
                "number_boxes = 16\n",
                "with open(\"paths.yaml\", \"r\") as paths:\n",
                "\tpaths = yaml.safe_load(paths)\n",
                "\tprepared1_dir = Path(paths[\"datasets_prepared_dir\"]) / dataset_prep\n",
                "\tprepared_pieces_dir = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_prep} cut_{number_boxes}pieces separate_boxes\"\n",
                "\tprepared_pieces_dir.mkdir(parents=True, exist_ok=True)\n",
                "cut_dataset_in_pieces(number_boxes, prepared1_dir, prepared_pieces_dir)\n",
                "# not required for testing:\n",
                "# prepare_dataset_for_2levels(dataset_name, number_boxes, \"t\", paths, prepared1_dir, prepared_pieces_dir)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for id in range(1,5):\n",
                "    pipeline(id, \"test_cut_pieces_pipeline small_long\", \"t\", nr_boxes_orig=number_boxes, model=model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
