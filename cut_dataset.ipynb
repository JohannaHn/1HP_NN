{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"dataset_medium_k_3e-10_1000dp inputs_gksi\"\n",
    "with open(\"paths.yaml\", \"r\") as paths:\n",
    "    paths = yaml.safe_load(paths)\n",
    "    prepared1_dir = Path(paths[\"datasets_prepared_dir\"]) / dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut dataset into x boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_boxes = 16\n",
    "number_datapoints = 10000\n",
    "prepared_pieces_dir = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_name} cut_{number_boxes}pieces separate_boxes\"\n",
    "prepared_pieces_dir.mkdir(parents=True, exist_ok=True)\n",
    "for box in range(number_boxes):\n",
    "    (prepared_pieces_dir / f\"Inputs Box {box}\").mkdir(parents=True, exist_ok=True)\n",
    "    (prepared_pieces_dir / f\"Label Box {box}\").mkdir(parents=True, exist_ok=True)\n",
    "shutil.copy(prepared1_dir / \"info.yaml\", prepared_pieces_dir / \"info.yaml\")\n",
    "\n",
    "j = 0\n",
    "for datapoint in zip((prepared1_dir / \"Inputs\").iterdir(), (prepared1_dir / \"Labels\").iterdir()):\n",
    "    input = torch.load(datapoint[0])\n",
    "    label = torch.load(datapoint[1])\n",
    "    name = datapoint[0].stem\n",
    "\n",
    "    input_boxes = []\n",
    "    label_boxes = []\n",
    "    for i in range(number_boxes):\n",
    "        len_box = input.shape[1] // number_boxes\n",
    "        input_boxes.append(input[:, i * len_box : (i + 1) * len_box, :])\n",
    "        label_boxes.append(label[:, i * len_box : (i + 1) * len_box, :])\n",
    "\n",
    "\n",
    "    for i in range(number_boxes):\n",
    "        torch.save(input_boxes[i], prepared_pieces_dir / f\"Inputs Box {i}\" / f\"{name}.pt\",)\n",
    "        torch.save(label_boxes[i], prepared_pieces_dir / f\"Label Box {i}\" / f\"{name}.pt\",)\n",
    "    \n",
    "    j+=1\n",
    "    if j == number_datapoints:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store boxes for 2 levels in 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/scratch/sc/pillerls/datasets_prepared/dataset_medium_k_3e-10_1000dp inputs_gksi cut_16pieces separate_boxes 1st level/Labels')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare 1st level\n",
    "prepared_dir_1stlevel = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_name} cut_{number_boxes}pieces separate_boxes 1st level\"\n",
    "prepared_dir_1stlevel.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "shutil.copy(prepared_pieces_dir / \"info.yaml\", prepared_dir_1stlevel / \"info.yaml\")\n",
    "shutil.copytree(prepared_pieces_dir / \"Inputs Box 0\", prepared_dir_1stlevel / \"Inputs\")\n",
    "shutil.copytree(prepared_pieces_dir / \"Label Box 0\", prepared_dir_1stlevel / \"Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Permeability X [m^2]': {'index': 2, 'max': 2.9672317380935453e-10, 'mean': 8.87306061958526e-11, 'min': 1.0086227859862351e-11, 'norm': 'Rescale', 'std': 7.734657359037556e-11}, 'Pressure Gradient [-]': {'index': 1, 'max': -0.0015021893195807934, 'mean': -0.002550203585997224, 'min': -0.0034940664190799, 'norm': 'Rescale', 'std': 0.0005860578967258334}, 'Temperature [C]': {'index': 0, 'max': 15.601107597351074, 'mean': 10.706022262573242, 'min': 10.600000381469727, 'norm': 'Rescale', 'std': 0.33781468868255615}}\n"
     ]
    }
   ],
   "source": [
    "# prepare 2nd level\n",
    "prepared_dir_2ndlevel = Path(paths[\"datasets_prepared_dir\"]) / f\"{dataset_name} cut_{number_boxes}pieces separate_boxes 2nd level gkt\"\n",
    "prepared_dir_2ndlevel.mkdir(parents=True, exist_ok=True)\n",
    "(prepared_dir_2ndlevel / \"Inputs\").mkdir(parents=True, exist_ok=True)\n",
    "(prepared_dir_2ndlevel / \"Labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "info = yaml.safe_load(open(prepared_dir_1stlevel / \"info.yaml\", \"r\"))\n",
    "info_k    = deepcopy(info[\"Inputs\"][\"Permeability X [m^2]\"])\n",
    "info_T    = deepcopy(info[\"Labels\"][\"Temperature [C]\"])\n",
    "info[\"Inputs\"][\"Temperature [C]\"] = info_T\n",
    "info[\"Inputs\"][\"Permeability X [m^2]\"] = info_k\n",
    "info[\"Inputs\"][\"Pressure Gradient [-]\"][\"index\"] = 1\n",
    "info[\"Inputs\"][\"Permeability X [m^2]\"][\"index\"] = 2\n",
    "info[\"Inputs\"][\"Temperature [C]\"][\"index\"] = 0\n",
    "# assert indices of inputs double\n",
    "idx_k = info[\"Inputs\"][\"Permeability X [m^2]\"][\"index\"]\n",
    "idx_t = info[\"Inputs\"][\"Temperature [C]\"][\"index\"]\n",
    "idx_g = info[\"Inputs\"][\"Pressure Gradient [-]\"][\"index\"]\n",
    "assert  idx_k != idx_t, \"indices of inputs double\"\n",
    "info[\"Inputs\"].pop(\"Material ID\")\n",
    "info[\"Inputs\"].pop(\"SDF\")\n",
    "info[\"Labels\"].pop(\"Liquid Pressure [Pa]\")\n",
    "print(info[\"Inputs\"])\n",
    "\n",
    "yaml.safe_dump(info, open(prepared_dir_2ndlevel / \"info.yaml\", \"w\"))\n",
    "\n",
    "for box in range(2, number_boxes-1):\n",
    "    for file_in_temp in (prepared_pieces_dir / f\"Label Box {box}\").iterdir():\n",
    "        file_id = int(file_in_temp.stem.split(\"_\")[1])\n",
    "        new_id = file_id + (box) * 1000\n",
    "        temp_in = torch.load(file_in_temp)[0]\n",
    "        file_inputs = prepared_pieces_dir / f\"Inputs Box {box}\" / f\"RUN_{file_id}.pt\"\n",
    "        file_label = prepared_pieces_dir / f\"Label Box {box+1}\" / f\"RUN_{file_id}.pt\"\n",
    "        p_in = torch.load(file_in_temp)[1]\n",
    "        k_in = torch.load(file_inputs)[1]\n",
    "        g_in = torch.load(file_inputs)[0]\n",
    "        inputs = torch.zeros([3, *p_in.shape])\n",
    "        inputs[idx_k] = k_in\n",
    "        inputs[idx_g] = g_in\n",
    "        inputs[idx_t] = temp_in#[-1:,:].repeat(int(1024/number_boxes), 1)\n",
    "\n",
    "        outputs = torch.zeros([1, p_in.shape[0]*2, p_in.shape[1]])\n",
    "        temp_out = torch.load(file_label)[0]\n",
    "        outputs[0] = torch.cat((temp_in, temp_out), dim=0)\n",
    "        if outputs[0, -1, 31] > 0.05:\n",
    "        \n",
    "            torch.save(inputs, prepared_dir_2ndlevel / \"Inputs\" / f\"RUN_{new_id}.pt\")\n",
    "\n",
    "            \n",
    "            torch.save(outputs, prepared_dir_2ndlevel / \"Labels\" / f\"RUN_{new_id}.pt\")\n",
    "\n",
    "            # plt.imshow(outputs[0])\n",
    "            # plt.colorbar()\n",
    "            # plt.show()\n",
    "            # plt.imshow(outputs[1])\n",
    "            # plt.colorbar()\n",
    "            # plt.show()\n",
    "\n",
    "        # print(inputs.shape, outputs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
